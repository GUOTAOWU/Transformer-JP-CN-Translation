{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228e2a13-fda5-41bd-9613-b7e08934c216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting jieba\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m19.2/19.2 MB\u001B[0m \u001B[31m68.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hBuilding wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=7245ee8156b70f33d4354de04053c3d8f5fbb425e33f8633fd009ead72fc270d\n",
      "  Stored in directory: /home/featurize/.cache/pip/wheels/37/08/79/ea7c0d2ca823affa13f89586a5a9eff8dd6ad589640396e1b5\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 必要なライブラリのインストール\n",
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9225ca36-79b5-4c20-aac9-1071834b4576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting sentencepiece\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fb/12/2f5c8d4764b00033cf1c935b702d3bb878d10be9f0b87f0253495832d85f/sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m46.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3a972d-804b-4523-85de-11bc79ff7336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting torchtext==0.4.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.1/53.1 kB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /environment/miniconda3/lib/python3.11/site-packages (from torchtext==0.4.0) (4.65.0)\n",
      "Requirement already satisfied: requests in /environment/miniconda3/lib/python3.11/site-packages (from torchtext==0.4.0) (2.31.0)\n",
      "Requirement already satisfied: torch in /environment/miniconda3/lib/python3.11/site-packages (from torchtext==0.4.0) (2.2.2)\n",
      "Requirement already satisfied: numpy in /environment/miniconda3/lib/python3.11/site-packages (from torchtext==0.4.0) (1.26.4)\n",
      "Requirement already satisfied: six in /environment/miniconda3/lib/python3.11/site-packages (from torchtext==0.4.0) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /environment/miniconda3/lib/python3.11/site-packages (from requests->torchtext==0.4.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /environment/miniconda3/lib/python3.11/site-packages (from requests->torchtext==0.4.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /environment/miniconda3/lib/python3.11/site-packages (from requests->torchtext==0.4.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /environment/miniconda3/lib/python3.11/site-packages (from requests->torchtext==0.4.0) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (4.11.0)\n",
      "Requirement already satisfied: sympy in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /environment/miniconda3/lib/python3.11/site-packages (from torch->torchtext==0.4.0) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /environment/miniconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.4.0) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /environment/miniconda3/lib/python3.11/site-packages (from jinja2->torch->torchtext==0.4.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /environment/miniconda3/lib/python3.11/site-packages (from sympy->torch->torchtext==0.4.0) (1.3.0)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchtext==0.4.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abedd84a-fc71-41ba-b084-c4eac3853e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import math\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.nn import TransformerEncoder, TransformerDecoder, TransformerEncoderLayer, TransformerDecoderLayer\n",
    "import io\n",
    "import time\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import sentencepiece as spm\n",
    "# 再現性のためにシードを固定\n",
    "torch.manual_seed(0)\n",
    "# GPUが使える場合はGPUを使用\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0454007-d1b1-4e05-9e44-4efe15884669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日中対訳データセットの読み込み\n",
    "df = pd.read_csv('zh-ja.bicleaner05.txt', sep='\\\\t', engine='python', header=None)\n",
    "trainzh = df[2].values.tolist()#[:10000]\n",
    "trainja = df[3].values.tolist()#[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa61380a-6ec1-40e5-bee7-1e6c7eaf849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese HS Code Harmonized Code System < HS编码 2905 无环醇及其卤化、磺化、硝化或亚硝化衍生物 HS Code List (Harmonized System Code) for US, UK, EU, China, India, France, Japan, Russia, Germany, Korea, Canada ...\n",
      "Japanese HS Code Harmonized Code System < HSコード 2905 非環式アルコール並びにそのハロゲン化誘導体、スルホン化誘導体、ニトロ化誘導体及びニトロソ化誘導体 HS Code List (Harmonized System Code) for US, UK, EU, China, India, France, Japan, Russia, Germany, Korea, Canada ...\n"
     ]
    }
   ],
   "source": [
    "# データの確認\n",
    "print(trainzh[500])\n",
    "print(trainja[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "438d142d-0ef8-4f8c-9628-70dfcf91ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentencePieceトークナイザのモデル読み込み\n",
    "zh_tokenizer = spm.SentencePieceProcessor(model_file='spm.zh.nopretok.model')\n",
    "ja_tokenizer = spm.SentencePieceProcessor(model_file='spm.ja.nopretok.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42e27558-82e6-4cf6-80bc-fa1b4dea528e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45,\n",
       " 11042,\n",
       " 22559,\n",
       " 45,\n",
       " 22523,\n",
       " 21367,\n",
       " 23664,\n",
       " 23194,\n",
       " 13313,\n",
       " 1483,\n",
       " 29132,\n",
       " 22977,\n",
       " 2723,\n",
       " 29132,\n",
       " 13313,\n",
       " 11726,\n",
       " 23044,\n",
       " 26716,\n",
       " 22631,\n",
       " 19869,\n",
       " 16973,\n",
       " 22835,\n",
       " 11042,\n",
       " 22559,\n",
       " 22828,\n",
       " 22615,\n",
       " 4776]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 中国語のトークン化テスト\n",
    "zh_tokenizer.encode(\"年金 在日本居住的20岁到60岁的人必须加入公共年金制度。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25d86e39-5a77-4bf6-b437-65641067d560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 6866,\n",
       " 714,\n",
       " 12628,\n",
       " 210,\n",
       " 1550,\n",
       " 306,\n",
       " 1077,\n",
       " 5231,\n",
       " 1092,\n",
       " 830,\n",
       " 3,\n",
       " 7503,\n",
       " 6866,\n",
       " 786,\n",
       " 10,\n",
       " 8556,\n",
       " 4600,\n",
       " 5]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 日本語のトークン化テスト\n",
    "ja_tokenizer.encode(\"年金 日本に住んでいる20歳~60歳の全ての人は、公的年金制度に加入しなければなりません。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65beceb7-ac1f-47f7-a071-e2a5fd0bdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 語彙集（ボキャブラリー）の構築関数\n",
    "def build_vocab(sentences, tokenizer):\n",
    "    counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        counter.update(tokenizer.encode(sentence, out_type=str))\n",
    "    # 特殊トークン（未知語、パディング、文頭、文末）を追加\n",
    "    return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "# 語彙集の作成\n",
    "ja_vocab = build_vocab(trainja, ja_tokenizer)\n",
    "zh_vocab = build_vocab(trainzh, zh_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0f64bea-11b7-4987-81d0-a135f0bcf142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをテンソル（数値）に変換する処理\n",
    "def data_process(ja, en):\n",
    "    data = []\n",
    "    for (raw_ja, raw_en) in zip(ja, en):\n",
    "        # 文末の改行を削除し、ID列に変換\n",
    "        ja_tensor_ = torch.tensor([ja_vocab[token] for token in ja_tokenizer.encode(raw_ja.rstrip(\"\\n\"), out_type=str)],\n",
    "                                  dtype=torch.long)\n",
    "        zh_tensor_ = torch.tensor([zh_vocab[token] for token in zh_tokenizer.encode(raw_en.rstrip(\"\\n\"), out_type=str)],\n",
    "                                  dtype=torch.long)\n",
    "        data.append((ja_tensor_, zh_tensor_))\n",
    "    return data\n",
    "\n",
    "train_data = data_process(trainja, trainzh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7ff8f26-5a4b-4cd9-87ed-78cae5de26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチサイズと特殊トークンのID定義\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "PAD_IDX = ja_vocab['<pad>']\n",
    "BOS_IDX = ja_vocab['<bos>']\n",
    "EOS_IDX = ja_vocab['<eos>']\n",
    "# バッチデータの生成関数（パディング処理含む）\n",
    "def generate_batch(data_batch):\n",
    "    ja_batch, zh_batch = [], []\n",
    "    for (ja_item, zh_item) in data_batch:\n",
    "        # 文頭と文末にトークンを追加\n",
    "        ja_batch.append(torch.cat([torch.tensor([BOS_IDX]), ja_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        zh_batch.append(torch.cat([torch.tensor([BOS_IDX]), zh_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        # パディングを行って長さを揃える\n",
    "    ja_batch = pad_sequence(ja_batch, padding_value=PAD_IDX)\n",
    "    zh_batch = pad_sequence(zh_batch, padding_value=PAD_IDX)\n",
    "    return ja_batch, zh_batch\n",
    "# データローダーの作成\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7adc418-5dd4-4a72-bfa9-e03b2ef780bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformerモデルの定義\n",
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
    "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        # エンコーダ層\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        # デコーダ層\n",
    "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, nhead=NHEAD,\n",
    "                                                dim_feedforward=dim_feedforward)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "        # 出力層\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        # 埋め込み層（Embedding）\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        # 位置エンコーディング\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        # 順伝播処理\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "419dc30d-7c3a-403b-bb62-6df729430f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置エンコーディング（Positional Encoding）クラス\n",
    "# Transformerは順序情報を持たないため、位置情報を加算する\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "# トークン埋め込みクラス\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e73cd72a-2835-4946-8607-f6b81f337f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マスク生成関数\n",
    "# デコーダが未来の単語を見ないようにするためのマスク（Look-ahead Mask）などを作成\n",
    "def generate_square_subsequent_mask(sz):\n",
    "\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    \n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6c9a2e54-0757-48dd-90d2-c3f124221632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "SRC_VOCAB_SIZE = len(ja_vocab)\n",
    "TGT_VOCAB_SIZE = len(zh_vocab)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 16\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "NUM_EPOCHS = 16\n",
    "# モデルのインスタンス化\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "# パラメータの初期化（Xavier Initialization）\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(device)\n",
    "# 損失関数の定義（パディング部分は無視する）\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "# 最適化アルゴリズム（Adam）の設定\n",
    "optimizer = torch.optim.Adam(\n",
    "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
    ")\n",
    "# 1エポック分の学習関数\n",
    "def train_epoch(model, train_iter, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in enumerate(train_iter):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                       src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(train_iter)\n",
    "\n",
    "# 検証関数\n",
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in enumerate(val_iter):\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                       src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        \n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "    return losses / len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed2e516f-f99a-4fac-847f-4830e2825a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]/environment/miniconda3/lib/python3.11/site-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "  6%|▋         | 1/16 [03:50<57:32, 230.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 4.498, Epoch time = 230.192s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [07:42<54:03, 231.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 3.510, Epoch time = 232.688s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [11:45<51:17, 236.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 3.096, Epoch time = 242.716s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4/16 [15:44<47:29, 237.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 2.796, Epoch time = 238.662s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [19:40<43:27, 237.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 2.574, Epoch time = 236.348s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [24:06<41:08, 246.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 2.408, Epoch time = 265.779s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [28:06<36:40, 244.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 2.293, Epoch time = 239.749s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [32:09<32:32, 244.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 2.200, Epoch time = 243.011s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [36:05<28:10, 241.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 2.116, Epoch time = 236.068s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [39:59<23:55, 239.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 2.041, Epoch time = 234.184s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [43:57<19:55, 239.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 1.979, Epoch time = 238.383s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [47:47<15:45, 236.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 1.926, Epoch time = 230.122s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [51:45<11:50, 236.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 1.878, Epoch time = 237.577s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [55:41<07:52, 236.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 1.836, Epoch time = 235.804s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [59:59<04:03, 243.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 1.797, Epoch time = 258.346s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [1:04:21<00:00, 241.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 1.763, Epoch time = 262.011s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 学習の実行ループ\n",
    "for epoch in tqdm.tqdm(range(1, NUM_EPOCHS + 1)):\n",
    "    start_time = time.time()  \n",
    "    train_loss = train_epoch(transformer, train_iter, optimizer)\n",
    "    end_time = time.time()  \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, \"\n",
    "           f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94aba97c-a1be-4eae-8481-e0db6083e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 貪欲法によるデコード（翻訳文生成）関数\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "# 翻訳実行のラッパー関数\n",
    "def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
    "    model.eval()  \n",
    "    tokens = [BOS_IDX] + [src_vocab.stoi[tok] for tok in src_tokenizer.encode(src, out_type=str)] + [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1))\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join([tgt_vocab.itos[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bd13c273-f7ba-4dd7-a74f-bfb558055044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの抽出（全体の1%を使用）\n",
    "TEST_RATIO = 0.01 \n",
    "NUM_SAMPLES = 100 \n",
    "import random\n",
    "random.seed(42) \n",
    "test_data = random.sample(train_data, min(NUM_SAMPLES, int(len(train_data) * TEST_RATIO)))\n",
    "\n",
    "test_iter = DataLoader(test_data, batch_size=1,\n",
    "                       shuffle=False, collate_fn=generate_batch)\n",
    "\n",
    "# BLEUスコア計算関数（機械翻訳の評価指標）\n",
    "def calculate_bleu(pred_tokens, target_tokens):\n",
    "    pred_set = set(pred_tokens)\n",
    "    target_set = set(target_tokens)\n",
    "    correct = sum(1 for token in pred_tokens if token in target_set)\n",
    "    precision = correct / len(pred_tokens) if len(pred_tokens) > 0 else 0\n",
    "    bleu = precision * math.exp(min(0, 1 - len(target_tokens) / len(pred_tokens))) if precision > 0 else 0\n",
    "    return bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "104d2175-8935-4b2a-b016-edbda6c0f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルの評価関数\n",
    "def evaluate_trained_model(model, test_loader, num_samples=None):\n",
    "    model.eval()\n",
    "    total_bleu = 0\n",
    "    total_exact_match = 0\n",
    "    sample_count = 0\n",
    "    \n",
    "    examples = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (src, tgt) in enumerate(test_loader):\n",
    "            if num_samples and idx >= num_samples:\n",
    "                break\n",
    "                \n",
    "            ja_sentence = ' '.join([ja_vocab.itos[token.item()] for token in src.squeeze(1) \n",
    "                                  if token.item() not in [BOS_IDX, EOS_IDX, PAD_IDX]])\n",
    "            \n",
    "            target_zh = [zh_vocab.itos[token.item()] for token in tgt.squeeze(1) \n",
    "                        if token.item() not in [BOS_IDX, EOS_IDX, PAD_IDX]]\n",
    "            target_zh_str = ''.join(target_zh)  \n",
    "            \n",
    "            src_mask = (torch.zeros(src.shape[0], src.shape[0])).type(torch.bool).to(device)\n",
    "            translated = greedy_decode(model, src, src_mask, max_len=50, start_symbol=BOS_IDX).flatten()\n",
    "            \n",
    "            pred_zh = [zh_vocab.itos[token.item()] for token in translated \n",
    "                      if token.item() not in [BOS_IDX, EOS_IDX, PAD_IDX]]\n",
    "            pred_zh_str = ''.join(pred_zh)  \n",
    "            \n",
    "            bleu, precision, recall = calculate_bleu(pred_zh, target_zh)\n",
    "            \n",
    "            exact_match = int(pred_zh_str == target_zh_str)\n",
    "            \n",
    "            total_bleu += bleu\n",
    "            total_exact_match += exact_match\n",
    "            sample_count += 1\n",
    "            \n",
    "            if idx < 5:\n",
    "                # 以下のキーは出力結果の各項目に対応しています\n",
    "                examples.append({\n",
    "                    \"日语\": ja_sentence,# 日本語原文\n",
    "                    \"预测中文\": pred_zh_str,# 予測された中国語訳\n",
    "                    \"真实中文\": target_zh_str,# 正解の中国語訳\n",
    "                    \"完全匹配\": \"是\" if exact_match else \"否\",# 完全一致したか（是=はい, 否=いいえ）\n",
    "                    \"BLEU分数\": f\"{bleu:.4f}\"# BLEUスコア\n",
    "                })\n",
    "        \n",
    "    avg_bleu = total_bleu / sample_count if sample_count > 0 else 0\n",
    "    exact_match_rate = total_exact_match / sample_count if sample_count > 0 else 0\n",
    "    # モデル評価結果の出力\n",
    "    print(\"\\n模型性能评估:\")# 日本語訳：モデル性能評価\n",
    "    print(f\"测试句子数: {sample_count}\")# 日本語訳：テストした文の数\n",
    "    print(f\"平均BLEU分数: {avg_bleu:.4f}\")# 日本語訳：平均BLEUスコア\n",
    "    \n",
    "    return avg_bleu, exact_match_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "832790ea-5b09-42ae-8fb9-19e67a37bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始评估训练好的模型...\n",
      "\n",
      "模型性能评估:\n",
      "测试句子数: 100\n",
      "平均BLEU分数: 0.5414\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n开始评估训练好的模型...\")# 日本語訳：学習済みモデルの評価を開始します...\n",
    "avg_bleu, exact_match_rate = evaluate_trained_model(transformer, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79d5136-bde8-4126-b48b-5238c1154afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_日本 便利店 的 服务 真 的 令 人 佩服\n"
     ]
    }
   ],
   "source": [
    "translated_sentence = translate(\n",
    "    transformer, \n",
    "    \"日本のコンビニのサービスには 本当に感心させられる。\",  \n",
    "    ja_vocab, \n",
    "    zh_vocab, \n",
    "    ja_tokenizer  \n",
    ")\n",
    "\n",
    "print(translated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a594b-e088-49be-b735-fac14b5b9658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f58cd-456e-465f-b5fd-05fe17353378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
